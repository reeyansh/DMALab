{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walkthrough of Data Science process - Traveler\n",
    "\n",
    "### * Goal: Predict the country that users will make their first booking in, based on some basic user profile data.\n",
    "\n",
    "#### [1] Pre-processing: Assessing and analyzing data, cleaning, transforming and adding new features\n",
    "#### [2] Learning model: Constructing and testing learning model\n",
    "#### [3] Post-processing: Creating final predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone1: Understanding the Data\n",
    "\n",
    "#### Formulate range of questions including (but not limited to):\n",
    "\n",
    "    1. What features (columns) does the dataset contain?\n",
    "    2. How many records (rows) have been provided?\n",
    "    3. What format is the data in (e.g. what format are the dates provided, are there numerical values, what do the different categorical values look like)?\n",
    "    4. Are there missing values?\n",
    "    5. How do the different features relate to each other?\n",
    "    \n",
    "    Note: Look into the csv files provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing the Dataset\n",
    "\n",
    "    1. train_users_2.csv  – This dataset contains data on Traveler users, including the destination countries. Each row represents one user with the columns containing various information such the users’ ages and when they signed up. This is the primary dataset used to train the model.\n",
    "    \n",
    "    2. test_users.csv – This dataset also contains data on Traveler users, in the same format as train_users_2.csv, except without the destination country. These are the users for which final prediction model need to be tested.\n",
    "    \n",
    "    3. sessions.csv – This data is supplementary data that can be used to train the model and make the final predictions. It contains information about the actions (e.g. clicked on a listing, updated a  wish list, ran a search etc.) taken by the users in both the testing and training datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Exploring Traveler data\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline \n",
    "data =pd.read_csv(\"./traveler/train_users_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at sample data what can be observed (but not limited)\n",
    "\n",
    "    1. Missing values in the age column and date_first_booking column\n",
    "        - ? need to be filled or the rows excluded altogether\n",
    "\n",
    "    2. Most of the columns provided contain categorical data\n",
    "        - ? 11 of the 16 columns provided appear to be categorical\n",
    "        - Whats the problem? Most algs used in classification do not handle categorical data well. \n",
    "        - Solution: In data transformation, find ways to change data into forms more suitable for classification. \n",
    "\n",
    "    3. The timestamp_first_active column looks to be a full timestamp\n",
    "        - ? For example 20090609231247 looks like it should be 2009-06-09 23:12:47\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the structure of the data\n",
    " ### 1. Country Destination Values\n",
    "   ##### country_destination (Most important column) \n",
    "   ##### Why? - Looking at the number of records that fall into each category can help provide some insights into how the model should be constructed as well as pitfalls to avoid.\n",
    "<img src=\"./images/User_by_Destination.png\" height=\"400\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Looking at the breakdown of the data, one thing that immediately stands out is that almost 90% of users fall into two categories, that is, they are either yet to make a booking (NDF) or they made their first booking in the US. \n",
    "\n",
    "##### What’s more, breaking down these percentage splits by year reveals that the percentage of users yet to make a booking increases each year and reached over 60% in 2014.\n",
    "\n",
    "<img src=\"./images/User_by_Destination_and_Year.png\" height=\"400\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary for building a learning model:\n",
    "   ##### [1] By analysis we observe that the spread of categories (yearwise) might have changed over time.\n",
    "   ##### Since the final predictions will be made against user data from 2014 onwards, we can focus on more recent data for training the learning model as it is more likely to resemble the test data.\n",
    "   ##### [2] Since vast majority of users fall into 2 categories ('NDF' and 'US') there is a risk that if the learning model is too generalized, it will select one of these two categories for every prediction. \n",
    "   ##### Important to ensure that the training data has enough information to build a learning model that will predict other categories as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Account Creation Dates\n",
    "##### date_account_created column – how values have changed over time?\n",
    "<img src=\"./images/Accounts_Created_Over_Time.png\" height=\"400\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "   ##### [1] By analysis we observe that there is an explosive growth, averaging over 10% growth in new accounts create per month. \n",
    "   ##### [2] In 2014 there is rapid increase from the year before.\n",
    "   ##### In fact, we can limit considering the training data to accounts created from Jan 2013 onwards (70% will still be included)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Age Breakdown\n",
    "#### Data Quality issues \n",
    "##### - significant number of users reported their ages well over 100, \n",
    "##### - a significant number of users reported their ages as over 1000.\n",
    "<img src=\"./images/Reported_Ages_of_Users.png\" height=\"400\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "   ##### [1] Appears that a number of users have reported their birth year instead of their age.\n",
    "   ##### [2] Significant numbers of users reporting their age as 105 and 110.\n",
    "   ###### Why? - might be some users intentionally entered their age incorrectly for privacy reasons.\n",
    "   ###### These are errors and needs to be addressed.\n",
    "   ##### [3] Another issue with the age column is that sometimes age has not been reported at all.\n",
    "    \n",
    "   #### Check missing ages? \n",
    "   ##### Large number of missing values in all years.\n",
    "   <img src=\"./images/Missing_Ages.png\" height=\"400\" width=\"500\"/>\n",
    "   #### Note: While cleaning the data, need to decide what to do with these missing values.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. First Device Type\n",
    "#### first_device_used column\n",
    "<img src=\"./images/First_Device_Used.png\" height=\"400\" width=\"500\"/>\n",
    "\n",
    "### Summary:\n",
    "##### [1] Windows users have increased significantly as a percentage of all users.\n",
    "##### [2] iPhone users have tripled.\n",
    "##### [3] users using ‘Other/unknown’ devices have gone from the second largest group to less than 5% of users.\n",
    "\n",
    "#### Again we can notice that the recent data is likely to be most useful for building the learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other columns\n",
    "### HW - Give a look on other columns and see how they can also help in building an accurate classification learning model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part - Focus on Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] Fixing up formats - \n",
    "   ##### timestamp_first_active column contained numbers like 20090609231247 instead of timestamps in the expected format: 2009-06-09 23:12:47\n",
    "### [2] Filling in missing values \n",
    "### [3] Correcting erroneous values - \n",
    "   ##### 'gender' column where someone has entered a number, or an 'age' column where someone has entered a value well over 100. \n",
    "### [4] Standardizing categories (correcting erronous values) - \n",
    "   ##### spelling mistakes, language differences or other factors will result in a given answer being provided in multiple ways.\n",
    "   ###### Eg: data on country of birth, if users are not provided with a standardized list of countries, the data will inevitably contain multiple spellings of the same country (e.g. USA, United States, U.S. and so on)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Data - Solutions\n",
    "### [1] Deleting/Ignoring rows with missing values\n",
    "   ##### [a] If more than 10% of data to be deleted, then try reconsidering.\n",
    "   ##### [b] Be confident that the rows being deleted do not contain information that is not contained in other rows.\n",
    "   ##### Eg: For example, in the dataset we observe that many users have not provided their age. \n",
    "   ##### Can we assume that the people who chose not to provide their age are the same as the users who did? \n",
    "   ##### Or are they likely to represent a different type of user, perhaps an older and more privacy conscious user, and therefore a user that is likely to make different choices on which countries to visit? \n",
    "   ##### If the answer is the latter, we probably do not want to just delete the records.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] Filling in the Values\n",
    "##### What value to use?\n",
    "##### Depends on a range of factors, including the type of data we are trying to fill.\n",
    "##### Categorical: If the data is categorical (i.e. countries, device types, etc.), it may make sense to simply create a new category that will represent ‘unknown’.\n",
    "##### Another option may be to fill the values with the most common value for that column (the mode).\n",
    "#### Since these are broad methods for filling the missing values, this may oversimplify your data and/or make your final learning model less accurate.\n",
    "\n",
    "##### Numerical: For example age column, we could use mean or median to fill values.\n",
    "##### Or, take an average based on some other criteria – for example filling the missing age values based on an average age for users that selected the same country_destination.\n",
    "\n",
    "##### Note: For both types of data, we can use far more complicaed methods to impute the missing values. There are endless no. of ways..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning efforts on two files –\n",
    " train_users_2.csv and test_users.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Loading the data\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Reading data...\")\n",
    "train_file = \"./traveler/train_users_2.csv\"\n",
    "df_train = pd.read_csv(train_file, header = 0,index_col=None)\n",
    "\n",
    "test_file = \"./traveler/test_users.csv\"\n",
    "df_test = pd.read_csv(test_file, header = 0,index_col=None)\n",
    "\n",
    "# Combining into one dataset for cleaning\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "print(\"Reading data...completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cleaning the timestamps - Fixing up formats of dates\n",
    "\n",
    "#### Why to convert? - Reason: e.g. subtract one date from another, extract the month of the year from each date etc.\n",
    "\n",
    "#### In next exercise, we will find its importance when we start adding various new features to the training data based on this date information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fixing date formats in Pandas - to_datetime\n",
    "## Change dates to specific format\n",
    "print(\"Fixing timestamps...\")\n",
    "df_all['date_account_created'] = pd.to_datetime(df_all['date_account_created'], format='%Y-%m-%d')\n",
    "df_all['timestamp_first_active'] = pd.to_datetime(df_all['timestamp_first_active'], format='%Y%m%d%H%M%S')\n",
    "print(\"Fixing timestamps...completed\")\n",
    "df_all.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Removing booking date field\n",
    "\n",
    "#### Why? Notice howmany date fields are there?\n",
    "\n",
    "#### We converted two date fields to a format above.\n",
    "\n",
    "#### which one is not covered?\n",
    "\n",
    "#### Why? Reason - \n",
    "#### In training_users_2.csv, all the users that have a first booking country have a value in the date_first_booking column AND those who have not made a booking  (country_destination = NDF) the value is missing. \n",
    "#### In test_users.csv, the date_first_booking column is empty for all the records.\n",
    "\n",
    "\n",
    "## Summary: \n",
    "#### This column is not going to be useful for predicting which country a booking will be made. What is more, if we leave it in the training dataset when building the model, it will likely increase the chances that the model predicts NDF as those are the records without dates in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing date_first_booking column\n",
    "df_all.drop('date_first_booking', axis = 1, inplace = True)\n",
    "print(\"Droped date_first_booking column...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the Age column - Correcting erroneous values \n",
    "#### [1] Outliers - there are several age values that are clearly incorrect (unreasonably high or too low)\n",
    "#### Solution: replace these incorrect values with 'NaN' (changing incorrect values into missing values)\n",
    "#### [2] Missing values - there are a significant number of users who did not provide their age at all, they show up as NaN in the dataset\n",
    "#### Solution: lets change all the NaN values to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## Remove outliers function - [1]\n",
    "def remove_outliers(df, column, min_val, max_val):\n",
    "    col_values = df[column].values\n",
    "    df[column] = np.where(np.logical_or(col_values<=min_val, col_values>=max_val), np.NaN, col_values)\n",
    "    return df\n",
    "## Fixing age column - [2]\n",
    "print(\"Fixing age column...\")\n",
    "df_all = remove_outliers(df = df_all, column = 'age', min_val = 15, max_val = 90)\n",
    "df_all['age'].fillna(-1, inplace = True)\n",
    "print(\"Fixing age column...completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## HW - there are several more ways to fill in the missing values in the age column, try and list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify and fill additional columns with missing values - Filling in missing values \n",
    "#### One such column is first_affiliate_tracked has missing values\n",
    "#### Solution: follow same procedure as above (change all the NaN values to -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill first_affiliate_tracked column\n",
    "print(\"Filling first_affiliate_tracked column...\")\n",
    "df_all['first_affiliate_tracked'].fillna(-1, inplace=True)\n",
    "print(\"Filling first_affiliate_tracked column...completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Breaking Stage - Output\n",
    "## What does the data look like after all these changes? \n",
    "## Sample of some rows from cleaned dataset\n",
    "df_all.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Is that all?\n",
    "#### Not really - this is just a small work of cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Next?\n",
    "### Aim: Focus on transforming the data and feature extraction\n",
    "##### Why? To make better prediction learning model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
